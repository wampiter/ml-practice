{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "During training, randomly zeroes some of the elements of the input\n",
       "tensor with probability :attr:`p` using samples from a Bernoulli\n",
       "distribution. Each channel will be zeroed out independently on every forward\n",
       "call.\n",
       "\n",
       "This has proven to be an effective technique for regularization and\n",
       "preventing the co-adaptation of neurons as described in the paper\n",
       "`Improving neural networks by preventing co-adaptation of feature\n",
       "detectors`_ .\n",
       "\n",
       "Furthermore, the outputs are scaled by a factor of :math:`\\frac{1}{1-p}` during\n",
       "training. This means that during evaluation the module simply computes an\n",
       "identity function.\n",
       "\n",
       "Args:\n",
       "    p: probability of an element to be zeroed. Default: 0.5\n",
       "    inplace: If set to ``True``, will do this operation in-place. Default: ``False``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(*)`. Input can be of any shape\n",
       "    - Output: :math:`(*)`. Output is of the same shape as input\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Dropout(p=0.2)\n",
       "    >>> input = torch.randn(20, 16)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _Improving neural networks by preventing co-adaptation of feature\n",
       "    detectors: https://arxiv.org/abs/1207.0580\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/dropout.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        #multiply up by this to maintain activation total:\n",
    "        self.factor = 1/(1-p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            #probability of each neuron _not_ being dropped\n",
    "            probs = (1 - self.p) * torch.ones_like(x)\n",
    "            actives = torch.bernoulli(probs)\n",
    "            x = self.factor * actives * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = .8\n",
    "d, dt = [Dropout(p), nn.Dropout(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 4.0502, 0.0000],\n",
      "        [4.0048, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0000, 0.7069],\n",
      "        [0.0000, 2.9770, 0.0000],\n",
      "        [0.0000, 0.0000, 4.2918],\n",
      "        [0.0000, 3.9622, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(4,3)\n",
    "\n",
    "for f in [dt, d]:\n",
    "    print(f(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9207, 0.9467, 0.1414],\n",
      "        [0.2533, 0.5954, 0.4269],\n",
      "        [0.7610, 0.8100, 0.8584],\n",
      "        [0.8010, 0.7924, 0.5572]])\n",
      "tensor([[0.9207, 0.9467, 0.1414],\n",
      "        [0.2533, 0.5954, 0.4269],\n",
      "        [0.7610, 0.8100, 0.8584],\n",
      "        [0.8010, 0.7924, 0.5572]])\n"
     ]
    }
   ],
   "source": [
    "for f in [dt, d]:\n",
    "    f.eval()\n",
    "    print(f(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
